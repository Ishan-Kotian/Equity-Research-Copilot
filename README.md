# Equity Research Copilot

> Generativeâ€‘AI assistant that automates core equity research tasks â€” from sourcing disclosures and news to synthesizing insights and drafting analystâ€‘ready output.

---

## ğŸš€ Why this matters

* **Accelerate timeâ€‘toâ€‘insight:** Target **\~75% reduction** in initial research and report drafting time.
* **Scale analyst coverage:** Enable **up to 3Ã—** more companies per analyst through workflow automation.
* **Improve decision consistency:** Standardized analysis and templated outputs reduce variance and rework.

---

## âœ¨ What it does

* **Ingest**: Retrieve company disclosures (10â€‘K/Q), earnings transcripts, news, and pricing/ratio context.
* **Summarize**: Distill key sections (business overview, risks, segments) with reliable citations.
* **Sentiment**: Score narrative signals across filings and news to detect trend/inflection.
* **Valuation aides**: Surface ratio snapshots (P/E, P/S, EV/EBITDA) and DCF inputs for review.
* **Draft**: Generate an editable investment brief (talking points, risks, watchâ€‘items) for analysts.

> **Example prompt**: `Analyze AAPL and prepare a 1â€‘pager with overview, recent drivers, valuation context, and top 5 risks, citing important passages.`

---

## ğŸ§± Architecture overview

* **Orchestration / UI**: CLI + optional Streamlit/Flask frontâ€‘end
* **GenAI runtime**: **Azure AI Foundry** (model deployments, safety, monitoring)
* **Retrieval**: Vector store (Azure AI Search or pgvector) for Retrievalâ€‘Augmented Generation (RAG)
* **Pipelines**: ETL jobs to fetch and chunk source docs; metadata & citation tracking
* **Guardrails**: Content filters, sourceâ€‘attribution, confidence flags, humanâ€‘inâ€‘theâ€‘loop review
* **Tests**: Unit tests for agents, E2E smoke tests on a small ticker set

```
app/
  â”œâ”€ ui/                # Streamlit / Flask app (optional)
  â”œâ”€ agents/            # retrieval, synthesis, drafting
  â”œâ”€ pipelines/         # ingestion, chunking, indexing
  â”œâ”€ services/          # Azure, vector DB, storage
  â”œâ”€ eval/              # prompt evals, regression tests
  â””â”€ tests/             # unit + E2E
configs/
  â”œâ”€ app.toml           # feature flags
  â””â”€ connections.toml   # endpoints, collections, index names
data/
  â”œâ”€ raw/               # downloaded source docs (gitignored)
  â””â”€ index/             # vector artifacts (gitignored)
```

---

## ğŸ› ï¸ Tech stack

* **Azure AI Foundry** (model deployments & safety)
* **Python** (pandas, requests, pydantic, fastapi/streamlit)
* **Vector DB**: Azure AI Search **or** PostgreSQL + **pgvector**
* **Scheduling**: cron / GitHub Actions for ingestion refresh
* **Testing**: pytest + dataâ€‘driven prompt checks


---

## ğŸ” Key features

* **Cited answers**: Every claim links back to a paragraph in source docs.
* **Configurable templates**: 1â€‘pager, 3â€‘pager, or deck outline.
* **Valuation helpers**: Ratio snapshots and scaffolds for DCF inputs (manual review encouraged).
* **Sentiment tracks**: News vs. filings sentiment deltas to spot narrative shifts.
* **Analyst controls**: Redline edits, risk tagging, and watchâ€‘list export (CSV/Markdown).

---

## ğŸ“ˆ Example outputs

* **Company overview**: business model, segments, geography
* **Recent drivers**: product launches, guidance shifts, regulatory updates
* **Valuation context**: P/E, P/S, EV/EBITDA timeâ€‘series snapshot
* **Top risks**: sourced from Item 1A and recent transcripts


---

## ğŸ”’ Safety, accuracy & governance

* Retrievalâ€‘only answers for factual claims; no freeâ€‘form â€œknowledgeâ€ without a source
* Guardrails for sensitive content; explicit **confidence flags** on lowâ€‘evidence sections
* **Humanâ€‘inâ€‘theâ€‘loop**: Analysts approve draft output before publication
* Test set of tickers ensures prompt/output regressions are caught early

---

## ğŸ—ºï¸ Roadmap

* [ ] Broker transcript and Q\&A slot extraction
* [ ] KPI extraction by sector (e.g., DAUs/MAUs for internet, RPO for SaaS)
* [ ] Valuation table autoâ€‘refresh via scheduled data pulls
* [ ] Redteam evaluations and bias checks
* [ ] Multiâ€‘company compâ€‘table generation

---


## ğŸ™Œ Acknowledgments

Built as part of an MSBA project exploring how GenAI can **automate and standardize equity research** while keeping analysts **in control** of judgment and signâ€‘off.
